{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1348b2de-77bb-4f5e-91ce-3a1985f49c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Usando artefactos desde: artefactos/v1\n",
      "[demo] primeras predicciones: [{'proba_POS': 1.2036292426059978e-10, 'pred_num': 0, 'pred_label': 'NEG', 'threshold': 0.05}, {'proba_POS': 0.9999999999999998, 'pred_num': 1, 'pred_label': 'POS', 'threshold': 0.05}, {'proba_POS': 1.0, 'pred_num': 1, 'pred_label': 'POS', 'threshold': 0.05}]\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 12) Cargar artefactos y servir inferencia (mÃ­nimo) â€” robusto\n",
    "# =========================================\n",
    "import os, json, glob, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# (A) Utilidades\n",
    "def _latest_art_dir(root=\"artefactos\"):\n",
    "    if not os.path.isdir(root):\n",
    "        raise FileNotFoundError(f\"No existe la carpeta '{root}'.\")\n",
    "    subdirs = [d for d in glob.glob(os.path.join(root, \"*\")) if os.path.isdir(d)]\n",
    "    if not subdirs:\n",
    "        raise FileNotFoundError(f\"No hay versiones dentro de '{root}'.\")\n",
    "    # Por timestamp de modificaciÃ³n (mtimes) o por orden lexicogrÃ¡fico (TS)\n",
    "    subdirs.sort(key=lambda p: (os.path.getmtime(p), p), reverse=True)\n",
    "    return subdirs[0]\n",
    "\n",
    "# (B) Elegir versiÃ³n automÃ¡ticamente (puedes forzar una ruta concreta si quieres)\n",
    "ART_DIR = _latest_art_dir(\"artefactos\")\n",
    "print(f\"[info] Usando artefactos desde: {ART_DIR}\")\n",
    "\n",
    "# (C) Cargar artefactos obligatorios\n",
    "INPUT_SCHEMA = json.load(open(os.path.join(ART_DIR,\"input_schema.json\"), \"r\", encoding=\"utf-8\"))\n",
    "LABEL_MAP    = json.load(open(os.path.join(ART_DIR,\"label_map.json\"),    \"r\", encoding=\"utf-8\"))\n",
    "POLICY       = json.load(open(os.path.join(ART_DIR,\"decision_policy.json\"), \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "WINNER    = POLICY[\"winner\"]\n",
    "THRESHOLD = float(POLICY.get(\"threshold\", 0.5))\n",
    "REV_LABEL = {v:k for k,v in LABEL_MAP.items()}\n",
    "\n",
    "# (D) Cargar pipeline (nota: requiere imblearn si el pipeline tiene SMOTE)\n",
    "try:\n",
    "    import imblearn  # asegura disponibilidad de clases al deserializar\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "PIPE_PATH = os.path.join(ART_DIR, f\"pipeline_{WINNER}.joblib\")\n",
    "PIPE = joblib.load(PIPE_PATH)\n",
    "\n",
    "# (E) Compatibilidad de schema (nuevo/antiguo)\n",
    "if \"columns\" in INPUT_SCHEMA and \"dtypes\" in INPUT_SCHEMA:\n",
    "    FEATURES = INPUT_SCHEMA[\"columns\"]\n",
    "    DTYPES   = INPUT_SCHEMA[\"dtypes\"]\n",
    "else:  # legado: {col: dtype}\n",
    "    FEATURES = list(INPUT_SCHEMA.keys())\n",
    "    DTYPES   = INPUT_SCHEMA\n",
    "\n",
    "def _coerce_and_align(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Crear columnas faltantes\n",
    "    for c in FEATURES:\n",
    "        if c not in df.columns:\n",
    "            df[c] = np.nan\n",
    "    # Coaccionar tipos\n",
    "    for c in FEATURES:\n",
    "        t = str(DTYPES.get(c, \"object\")).lower()\n",
    "        if t.startswith((\"int\",\"float\")):\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "        elif t in (\"bool\",\"boolean\"):\n",
    "            df[c] = (df[c]\n",
    "                     .astype(\"string\")\n",
    "                     .str.strip()\n",
    "                     .str.lower()\n",
    "                     .map({\"true\": True, \"false\": False}))\n",
    "            df[c] = df[c].fillna(False).astype(bool)\n",
    "        else:\n",
    "            # normalizar strings: quitar espacios extremos\n",
    "            df[c] = df[c].astype(\"string\").str.strip()\n",
    "    # Reordenar columnas\n",
    "    return df[FEATURES]\n",
    "\n",
    "def predict_batch(records, thr=None):\n",
    "    thr = THRESHOLD if thr is None else float(thr)\n",
    "    if isinstance(records, dict):\n",
    "        records = [records]\n",
    "    df = _coerce_and_align(pd.DataFrame(records))\n",
    "    proba = PIPE.predict_proba(df)[:, 1]\n",
    "    yhat  = (proba >= thr).astype(int)\n",
    "    return [\n",
    "        {\"proba_POS\": float(p), \"pred_num\": int(y), \"pred_label\": REV_LABEL[int(y)], \"threshold\": thr}\n",
    "        for p, y in zip(proba, yhat)\n",
    "    ]\n",
    "\n",
    "# (F) Smoke test con samples (si existen)\n",
    "SAMPLES_JSON = os.path.join(ART_DIR, \"sample_inputs.json\")\n",
    "if os.path.exists(SAMPLES_JSON):\n",
    "    samples = json.load(open(SAMPLES_JSON, \"r\", encoding=\"utf-8\"))\n",
    "    demo = predict_batch(samples)[:3]\n",
    "    print(\"[demo] primeras predicciones:\", demo)\n",
    "else:\n",
    "    print(\"[demo] No hay sample_inputs.json; crea 1â€“3 registros para probar.\")\n",
    "\n",
    "# (G) Helpers de conveniencia\n",
    "def predict_one(dict_record, thr=None):\n",
    "    \"\"\"Atajo para un Ãºnico registro.\"\"\"\n",
    "    return predict_batch(dict_record, thr=thr)[0]\n",
    "\n",
    "def load_version(path):\n",
    "    \"\"\"Cargar artefactos desde una versiÃ³n especÃ­fica (e.g., artefactos/2025xxxx_HHMMSS).\"\"\"\n",
    "    global ART_DIR, INPUT_SCHEMA, LABEL_MAP, POLICY, WINNER, THRESHOLD, REV_LABEL, PIPE\n",
    "    ART_DIR = path\n",
    "    INPUT_SCHEMA = json.load(open(os.path.join(ART_DIR,\"input_schema.json\"), \"r\", encoding=\"utf-8\"))\n",
    "    LABEL_MAP    = json.load(open(os.path.join(ART_DIR,\"label_map.json\"),    \"r\", encoding=\"utf-8\"))\n",
    "    POLICY       = json.load(open(os.path.join(ART_DIR,\"decision_policy.json\"), \"r\", encoding=\"utf-8\"))\n",
    "    WINNER    = POLICY[\"winner\"]\n",
    "    THRESHOLD = float(POLICY.get(\"threshold\", 0.5))\n",
    "    REV_LABEL = {v:k for k,v in LABEL_MAP.items()}\n",
    "    try:\n",
    "        import imblearn\n",
    "    except Exception:\n",
    "        pass\n",
    "    PIPE = joblib.load(os.path.join(ART_DIR, f\"pipeline_{WINNER}.joblib\"))\n",
    "    print(f\"[info] Artefactos cargados desde: {ART_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40d97fb-ccbd-4d25-ad04-b66f1af0cb11",
   "metadata": {},
   "source": [
    "# Parte Modelado para algoritmos ML de clasificaciÃ³n\n",
    "Los datos ya vienen limpios y preparados para modelado.  \n",
    "Esta metodologÃ­a implementa una **lÃ­nea completa de desarrollo ML** (CRISP-DM adaptado), desde carga hasta despliegue.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 1 â€” Cargar datos y objetivo\n",
    "**Objetivo:** Leer dataset limpio, definir `TARGET`, mapear etiquetas (`NEGâ†’0`, `POSâ†’1`).  \n",
    "**Imprime:** `shape`, prevalencia de `POS`.  \n",
    "**Salida:** `df`, `X`, `y`.  \n",
    "**Exporta (opcional):** `reports/step1_overview_{ts}.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 2 â€” Split temprano (holdout 80/20)\n",
    "**Objetivo:** Separar `TRAIN/TEST` estratificado con `random_state` fijo.  \n",
    "**Imprime:** tamaÃ±os de `X_train/X_test`.  \n",
    "**Salida:** `X_train`, `X_test`, `y_train`, `y_test`.  \n",
    "**Exporta (opcional):** `reports/step2_split_meta_{ts}.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 3 â€” Preprocesamiento en pipeline\n",
    "**Objetivo:** Detectar `num_features`, `cat_nominal`, `cat_ordinal`;  \n",
    "crear `ColumnTransformer` con `StandardScaler` (numÃ©rico) +  \n",
    "`OneHotEncoder` (nominal) + `OrdinalEncoder` (ordinal).  \n",
    "Agregar **SMOTE** en el pipeline.  \n",
    "**Salida:** `preprocessor`, `build_pipe(model)`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 4 â€” Modelos candidatos\n",
    "**Objetivo:** Definir los modelos base:  \n",
    "`LRN, LDA, KNN, GNB, DTS, RFS, NNM (MLP), XGB, LGB, CAT`.  \n",
    "**Salida:** `candidates`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 5 â€” Baseline con CV (sin tuning)\n",
    "**Objetivo:** Evaluar candidatos con `StratifiedKFold(5)` dentro del pipeline (`prepâ†’smoteâ†’modelo`).  \n",
    "**MÃ©tricas:** `ACC`, `BALACC`, `PREC`, `REC`, `F1 (macro)`, `ROC-AUC`, `PR-AUC`, `MCC`.  \n",
    "**Ranking:** por `F1_macro`.  \n",
    "**Salida:** `baseline_df`, `baseline_best_name`, `baseline_best_model`.  \n",
    "**Exporta:** `reports/step5_baseline_metrics_{ts}.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 6 â€” Tuning con CV y elecciÃ³n preliminar\n",
    "**Objetivo:** `RandomizedSearchCV` con refit=`f1_macro`.  \n",
    "**Salida:** `tuning_df`, `best_name`, `final_pipe_opt`, `best_params`.  \n",
    "**Exporta:** `reports/step6_tuning_metrics_{ts}.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 7 â€” ComparaciÃ³n justa (solo CV)\n",
    "**Objetivo:** Re-evaluar **Baseline(best)** vs **Tuned(best)** con el mismo CV.  \n",
    "**Regla:** si Î”F1_macro < 0.005 â†’ **baseline**, caso contrario â†’ **tuned**.  \n",
    "**Salida:** `winner_name`, `winner_pipe`.  \n",
    "**Exporta:** `reports/step7_fair_compare_{ts}.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 8 â€” PolÃ­tica de decisiÃ³n (umbral en TRAIN)\n",
    "**Objetivo:** Determinar `BEST_THR` con **OOF probabilities** de `cross_val_predict`.  \n",
    "**Criterio:** `max F1_macro` (desempate: `balacc`, `prec`, `rec`).  \n",
    "**Salida:** `BEST_THR`, `thr_df`.  \n",
    "**Exporta:** `reports/step8_threshold_choice_{ts}.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 9 â€” EvaluaciÃ³n final en TEST\n",
    "**Objetivo:** Entrenar `winner_pipe` y evaluar con `BEST_THR`.  \n",
    "**Imprime:** mÃ©tricas globales + `classification_report` + matriz de confusiÃ³n.  \n",
    "**Salida:** `proba_test`, `y_pred`.  \n",
    "**Exporta:**  \n",
    "- `reports/step9_test_metrics_{ts}.csv`  \n",
    "- `reports/step9_confusion_matrix_{ts}.csv`  \n",
    "- Curvas ROC/PR en `.png` y `.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 10 â€” Interpretabilidad + Error Analysis + Fairness\n",
    "**Objetivo:** Explicar y auditar el modelo ganador.  \n",
    "**Incluye:**  \n",
    "- Importancias y **SHAP values** (segÃºn modelo).  \n",
    "- Listado de **10 FP/FN**.  \n",
    "- **Fairness** por subgrupos (`sexo`, `estado_civil`, `banco`, etc.):  \n",
    "  calcula disparidades Î”DP, Î”EO, Î”PP, Î”FPR.  \n",
    "**Exporta:**  \n",
    "- `reports/step10_feature_importance_{ts}.csv`  \n",
    "- `reports/step10_shap_meanabs_{ts}.csv`  \n",
    "- `reports/step10_false_positives_{ts}.csv`  \n",
    "- `reports/step10_false_negatives_{ts}.csv`  \n",
    "- `reports/step10_fairness_{attr}_{ts}.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 11 â€” Exportar artefactos (para despliegue)\n",
    "**Objetivo:** Empaquetar modelo, esquema y polÃ­tica.  \n",
    "**Genera:**  \n",
    "- `artefactos/{ts}/pipeline_{winner}.joblib`  \n",
    "- `input_schema.json`  \n",
    "- `label_map.json`  \n",
    "- `decision_policy.json`  \n",
    "- `model_card.md`  \n",
    "- `sample_inputs.json`, `sample_outputs.json`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 12 â€” Cargar artefactos y servir inferencia\n",
    "**Objetivo:** Reutilizar artefactos para predicciÃ³n batch o en servidor (Streamlit, API, etc.).  \n",
    "**Salida:** `predict_batch(records, thr=None)` y `predict_one(record)` listas para uso.  \n",
    "**Smoke test:** lee `sample_inputs.json` y muestra las primeras predicciones.\n",
    "\n",
    "---\n",
    "\n",
    "### Notas finales\n",
    "- MÃ©tricas en **decimales (0â€“1)**.  \n",
    "- Cada paso puede reejecutarse de forma independiente (persistencia por CSV/artefactos).  \n",
    "- El enfoque es **reproducible**, **explicable** y **listo para despliegue** en Streamlit Cloud o cualquier framework web.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaf76ba-81b6-4fac-b0fe-f6b69d32f6cb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db83a1ba-47f0-494c-8000-ff0b066c2591",
   "metadata": {},
   "source": [
    "# Parte Modelado para algoritmos ML de regresiÃ³n\n",
    "Los datos ya vienen limpios y preparados para modelado.  \n",
    "Esta lÃ­nea reproduce la metodologÃ­a de clasificaciÃ³n, adaptada a un **target continuo**.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 1 â€” Cargar datos y objetivo\n",
    "**Objetivo:** Leer dataset limpio, definir `TARGET` numÃ©rico (ej. `ingreso_mensual`, `precio`, `linea_credito`, etc.).  \n",
    "**Imprime:** `shape`, resumen estadÃ­stico (`describe()`), verificaciÃ³n de nulos.  \n",
    "**Salida:** `df`, `X`, `y`.  \n",
    "**Exporta (opcional):** `reports/step1_overview_{ts}.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 2 â€” Split temprano (holdout 80/20)\n",
    "**Objetivo:** Separar `TRAIN/TEST` con `random_state` fijo y sin estratificaciÃ³n.  \n",
    "**Imprime:** tamaÃ±os de `X_train/X_test`.  \n",
    "**Salida:** `X_train`, `X_test`, `y_train`, `y_test`.  \n",
    "**Exporta (opcional):** `reports/step2_split_meta_{ts}.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 3 â€” Preprocesamiento en pipeline\n",
    "**Objetivo:** Detectar `num_features`, `cat_nominal`, `cat_ordinal`;  \n",
    "crear `ColumnTransformer` con `StandardScaler` (numÃ©rico) +  \n",
    "`OneHotEncoder` (nominal) + `OrdinalEncoder` (ordinal).  \n",
    "No usa SMOTE (solo para clasificaciÃ³n).  \n",
    "**Salida:** `preprocessor`, `build_pipe(model)`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 4 â€” Modelos candidatos\n",
    "**Objetivo:** Definir modelos base de regresiÃ³n:  \n",
    "`LRN (LinearRegression)`, `RIDGE`, `LASSO`, `ENET`, `KNN`, `DTR`, `RFR`, `GBR`, `XGBR`, `LGBR`, `CATR`, `MLPRegressor`.  \n",
    "**Salida:** `candidates`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 5 â€” Baseline con CV (sin tuning)\n",
    "**Objetivo:** Evaluar candidatos con `KFold(5)` dentro del pipeline (`prepâ†’modelo`).  \n",
    "**MÃ©tricas:**  \n",
    "- `MAE`, `RMSE`, `MAPE`, `R2`, `EVS` (Explained Variance).  \n",
    "**Ranking:** por **`RMSE` (ascendente)** y **`R2` (descendente)**.  \n",
    "**Salida:** `baseline_df`, `baseline_best_name`, `baseline_best_model`.  \n",
    "**Exporta:** `reports/step5_baseline_metrics_{ts}.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 6 â€” Tuning con CV y elecciÃ³n preliminar\n",
    "**Objetivo:** `RandomizedSearchCV` con refit=`neg_root_mean_squared_error`.  \n",
    "**MÃ©tricas:** mismas del paso 5.  \n",
    "**Salida:** `tuning_df`, `best_name`, `final_pipe_opt`, `best_params`.  \n",
    "**Exporta:** `reports/step6_tuning_metrics_{ts}.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 7 â€” ComparaciÃ³n justa (solo CV)\n",
    "**Objetivo:** Comparar **Baseline(best)** vs **Tuned(best)** con el mismo CV.  \n",
    "**Regla:** si mejora de `RMSE` < 1% â†’ mantener baseline.  \n",
    "**Salida:** `winner_name`, `winner_pipe`.  \n",
    "**Exporta:** `reports/step7_fair_compare_{ts}.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 8 â€” PolÃ­tica de decisiÃ³n (anÃ¡lisis de residuales)\n",
    "**Objetivo:** Validar distribuciÃ³n de errores (bias y dispersiÃ³n).  \n",
    "**Incluye:** histograma y QQ-plot de residuales en TRAIN (OOF-CV).  \n",
    "**Salida:** `residuals_df` con columnas (`y_true`, `y_pred`, `residual`).  \n",
    "**Exporta:** `reports/step8_residuals_train_{ts}.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 9 â€” EvaluaciÃ³n final en TEST\n",
    "**Objetivo:** Evaluar `winner_pipe` en TEST.  \n",
    "**MÃ©tricas:** `MAE`, `RMSE`, `MAPE`, `R2`, `EVS`.  \n",
    "**Imprime:** resumen general + grÃ¡fico `y_true vs y_pred`.  \n",
    "**Salida:** `y_pred_test`, `residuals_test`.  \n",
    "**Exporta:**  \n",
    "- `reports/step9_test_metrics_{ts}.csv`  \n",
    "- `reports/step9_residuals_test_{ts}.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 10 â€” Interpretabilidad y Error Analysis\n",
    "**Objetivo:** Explicar el modelo ganador en tÃ©rminos de variables mÃ¡s influyentes.  \n",
    "**Incluye:**  \n",
    "- Importancias (modelos tipo Ã¡rbol o `permutation_importance`).  \n",
    "- SHAP values (`shap.Explainer` o nativo de CatBoost/LGB/XGB).  \n",
    "- AnÃ¡lisis de outliers (top residuales).  \n",
    "**Exporta:**  \n",
    "- `reports/step10_feature_importance_{ts}.csv`  \n",
    "- `reports/step10_shap_meanabs_{ts}.csv`  \n",
    "- `reports/step10_residuals_outliers_{ts}.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 11 â€” Exportar artefactos (despliegue)\n",
    "**Objetivo:** Empaquetar modelo, esquema y metadatos.  \n",
    "**Genera:**  \n",
    "- `artefactos/{ts}/pipeline_{winner}.joblib`  \n",
    "- `input_schema.json`  \n",
    "- `decision_policy.json` (sin umbral)  \n",
    "- `model_card.md`  \n",
    "- `sample_inputs.json`, `sample_outputs.json`.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 12 â€” Cargar artefactos y servir inferencia\n",
    "**Objetivo:** Reutilizar artefactos para predicciÃ³n batch o en servidor.  \n",
    "**Salida:** `predict_batch(records)` con valores continuos y errores absolutos relativos.  \n",
    "**Smoke test:** lee `sample_inputs.json` y muestra primeras predicciones.\n",
    "\n",
    "---\n",
    "\n",
    "### Notas finales\n",
    "- MÃ©tricas en **decimales o unidades reales** segÃºn variable.  \n",
    "- En regresiÃ³n, el foco es minimizar `RMSE` sin sacrificar interpretabilidad.  \n",
    "- SHAP y anÃ¡lisis de residuales ayudan a detectar sesgos sistemÃ¡ticos.  \n",
    "- El pipeline exportado es reutilizable para **Streamlit**, **API REST** o **Docker**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ccb9d7-e645-44b8-9507-ce7405beab39",
   "metadata": {},
   "source": [
    "# ðŸ§  MetodologÃ­a Integral de Modelado ML (ClasificaciÃ³n y RegresiÃ³n)\n",
    "\n",
    "Este proyecto implementa un flujo completo de **Machine Learning aplicado** bajo el enfoque **CRISP-DM adaptado**, optimizado para despliegue en entornos como **Streamlit Cloud**, **Docker**, o **API REST**.\n",
    "\n",
    "Los datos de entrada ya se asumen **limpios y validados**, listos para modelado supervisado.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ” Flujo General\n",
    "\n",
    "| Fase | PropÃ³sito | Resultados Clave |\n",
    "|------|------------|------------------|\n",
    "| **1. Carga y objetivo** | Leer dataset limpio, definir variable `TARGET`. | `df`, `X`, `y` |\n",
    "| **2. Split temprano** | Separar TRAIN/TEST (80/20, reproducible). | `X_train`, `X_test` |\n",
    "| **3. Preprocesamiento** | `StandardScaler`, `OneHotEncoder`, `OrdinalEncoder`, SMOTE (solo clasificaciÃ³n). | `build_pipe(model)` |\n",
    "| **4. Modelos candidatos** | Definir modelos base (clasificadores o regresores). | `candidates` |\n",
    "| **5. Baseline CV** | Evaluar desempeÃ±o inicial (5-fold CV). | MÃ©tricas, ranking baseline |\n",
    "| **6. Tuning CV** | `RandomizedSearchCV` (hiperparÃ¡metros crÃ­ticos). | `tuning_df`, `best_params` |\n",
    "| **7. ComparaciÃ³n justa** | Baseline vs Tuned con mismo CV. | `winner_pipe` |\n",
    "| **8. PolÃ­tica de decisiÃ³n** | Determinar umbral (`BEST_THR`) o analizar residuales. | `thr_df` / `residuals_df` |\n",
    "| **9. EvaluaciÃ³n final** | Entrenar ganador, evaluar en TEST. | MÃ©tricas finales + Curvas |\n",
    "| **10. Interpretabilidad** | SHAP, importancias, fairness, error analysis. | `feature_importance`, `fairness` |\n",
    "| **11. Exportar artefactos** | Guardar pipeline, schema, polÃ­ticas y ejemplos. | `/artefactos/{ts}/...` |\n",
    "| **12. Inferencia** | Cargar modelo y ejecutar predicciones. | `predict_batch(records)` |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“ˆ ClasificaciÃ³n\n",
    "- MÃ©tricas principales: `F1_macro`, `ROC-AUC`, `PR-AUC`, `MCC`.  \n",
    "- PolÃ­tica de decisiÃ³n ajusta **umbral Ã³ptimo** en TRAIN (OOF).  \n",
    "- Exporta artefactos con metadatos reproducibles.  \n",
    "- Fairness audit: Î” **DP**, **EO**, **PP**, **FPR** por subgrupos.\n",
    "\n",
    "## ðŸ“Š RegresiÃ³n\n",
    "- MÃ©tricas principales: `MAE`, `RMSE`, `MAPE`, `RÂ²`, `EVS`.  \n",
    "- Enfoque en **mÃ­nimo RMSE** y anÃ¡lisis de **residuales y outliers**.  \n",
    "- SHAP y permutaciÃ³n para interpretabilidad numÃ©rica.  \n",
    "- Exporta el pipeline sin umbral de decisiÃ³n.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§© Artefactos generados\n",
    "\n",
    "Cada ejecuciÃ³n produce una carpeta versionada:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a500faae-fe93-42e7-b941-ae66e7159b90",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Despliegue y uso\n",
    "1. Entrenar con los 12 pasos (clasificaciÃ³n o regresiÃ³n).  \n",
    "2. Exportar artefactos (`step11`).  \n",
    "3. Cargar modelo (`step12`) e integrar con:\n",
    "   - **Streamlit Cloud** (dashboard interactivo),\n",
    "   - **FastAPI / Flask** (servicio REST),\n",
    "   - **Docker Compose** (entorno reproducible).\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§® Reproducibilidad\n",
    "- `random_state` global en todos los pasos.  \n",
    "- Trazabilidad mediante `TS` (timestamp Ãºnico por ejecuciÃ³n).  \n",
    "- ExportaciÃ³n automÃ¡tica de mÃ©tricas, metadatos y artefactos.\n",
    "\n",
    "---\n",
    "\n",
    "## âš–ï¸ Buenas prÃ¡cticas\n",
    "- Evaluar **equilibrio F1 vs interpretabilidad**.  \n",
    "- Conservar datasets originales para auditorÃ­a.  \n",
    "- Documentar cambios de versiÃ³n (`model_card.md`).  \n",
    "- No modificar `pipeline.joblib` manualmente.\n",
    "\n",
    "---\n",
    "\n",
    "**Autor / Adaptador:**  \n",
    "MetodologÃ­a elaborada para enseÃ±anza y despliegue reproducible de modelos ML en entorno acadÃ©mico y profesional.  \n",
    "Compatible con datasets institucionales (`*.csv`) y flujos tipo CRISP-DM.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a94ec343-4e0f-489d-82e5-1ed74bef2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar la guiap_RegresionesPlantillav1.1 y la guiap_RegresionesPlantillav1.1-Despliegue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624b2908-e9f1-4371-a517-e0ec8f25d428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
